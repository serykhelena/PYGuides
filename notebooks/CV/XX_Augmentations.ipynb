{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альбументация данных - это такой подход, который используется для расширения обучающей выборки за счёт небольших изменений исходных данных. Например, сдвига данных, отражения по вертикальной/горизонтальной оси, изменение насыщенности пикселей (в случае картинок). \n",
    "\n",
    "Помимо увеличения количества данных в случае, когда их исходно мало, альбументация данных помогает избежать переобучения модели, а также помогает увелиить устойчивость работы модели (так как при обучении она видит разные модификации данных). \n",
    "\n",
    "Альбументацию можно применять к разным типам данных: \n",
    "- аудио\n",
    "- текст\n",
    "- изображения\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для альбументации изображений можно использовать:\n",
    "- геометрические преобразования - рандомная обрезка, поворот, отраждение и т.д. \n",
    "- изменение цветового пространства - изменение интенсивности, яркости пикселей и т.д.\n",
    "- фильтрация - размытие, изменение резкости и т.д.\n",
    "- рандомная зачистка - удаление части исходной картинки \n",
    "\n",
    "Для текста можно использовать: \n",
    "- перемешивание слов/предложений \n",
    "- перестановка слов - замена слов синонимами \n",
    "- манипуляция с текстом - перефразирование предложений\n",
    "\n",
    "Для аудио можно использовать: \n",
    "- добавление шумов \n",
    "- смещение каналов \n",
    "- изменение скорости \n",
    "\n",
    "Это только малая часть альбументаций, которую можно использовать. На самом деле их существует намного и намного больше. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = torchvision.datasets.MNIST(\n",
    "    \"data\", train=True, transform=None, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(src_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "for info in data:\n",
    "    img, label = info \n",
    "    images.append(np.array(img))\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Number of labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.ShiftScaleRotate(\n",
    "    shift_limit=0.3,\n",
    "    scale_limit=0,\n",
    "    rotate_limit=0,\n",
    "    interpolation=3,\n",
    "    border_mode=cv2.BORDER_CONSTANT,\n",
    "    p=0.9,\n",
    "    value=255,  # white background for better representation\n",
    ")\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.GaussianBlur(blur_limit=3, p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.HorizontalFlip(p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.InvertImg(p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.Compose(\n",
    "    [\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0.5,\n",
    "                    scale_limit=0,\n",
    "                    rotate_limit=0,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0,\n",
    "                    scale_limit=0.5,\n",
    "                    rotate_limit=0,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0,\n",
    "                    scale_limit=0,\n",
    "                    rotate_limit=50,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.InvertImg(p=0.9)\n",
    "            ]\n",
    "        )\n",
    "    ], \n",
    "    p=1, \n",
    ")\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbuAugmentationMultichannel:\n",
    "    def __init__(self, n_images: int):\n",
    "        ssr_params = dict(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=10,\n",
    "            interpolation=3,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "        self.description = [\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.GaussNoise(p=0.5),\n",
    "                    albu.MultiplicativeNoise(per_channel=True, p=0.3),\n",
    "                ],\n",
    "                p=0.4,\n",
    "            ),\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.MotionBlur(blur_limit=3, p=0.2),\n",
    "                    albu.MedianBlur(blur_limit=3, p=0.2),\n",
    "                    albu.GaussianBlur(blur_limit=3, p=0.2),\n",
    "                    albu.Blur(blur_limit=3, p=0.2),\n",
    "                ],\n",
    "                p=0.2,\n",
    "            ),\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.CLAHE(),\n",
    "                    albu.Sharpen(),\n",
    "                    albu.RandomBrightnessContrast(),\n",
    "                ],\n",
    "                p=0.3,\n",
    "            ),\n",
    "            albu.ShiftScaleRotate(**ssr_params, value=(0,)),\n",
    "        ]\n",
    "        images = {\"{}{}\".format(\"image\", i): \"image\" for i in range(n_images - 1)}\n",
    "        self.compose = albu.Compose(self.description, p=1, additional_targets=images)\n",
    "\n",
    "    def __call__(self, img: list) -> list:\n",
    "        images = {}\n",
    "        for i, image in enumerate(img):\n",
    "            imname = \"{}{}\".format(\"image\", i - 1) if i > 0 else \"image\"\n",
    "            images[imname] = image\n",
    "        transformed = self.compose(**images)\n",
    "        img = list(transformed.values())\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "\n",
    "* [Albumentations for image classififcation](https://albumentations.ai/docs/getting_started/image_augmentation/)\n",
    "* [List of albumentations](https://albumentations.ai/docs/getting_started/transforms_and_targets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c635c84616f3a4480481715ba1e3be1dbeefd6854b0fa1993fac6b8836a8b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
