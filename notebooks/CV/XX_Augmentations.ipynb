{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альбументация данных - это такой подход, который используется для расширения обучающей выборки за счёт небольших изменений исходных данных. Например, сдвига данных, отражения по вертикальной/горизонтальной оси, изменение насыщенности пикселей (в случае картинок). \n",
    "\n",
    "Помимо увеличения количества данных в случае, когда их исходно мало, альбументация данных помогает избежать переобучения модели, а также помогает увеличить устойчивость работы модели (так как при обучении она видит разные модификации данных). \n",
    "\n",
    "Альбументацию можно применять к разным типам данных: \n",
    "- аудио\n",
    "- текст\n",
    "- изображения\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для альбументации изображений можно использовать:\n",
    "- геометрические преобразования - рандомная обрезка, поворот, отражение и т.д. \n",
    "- изменение цветового пространства - изменение интенсивности, яркости пикселей и т.д.\n",
    "- фильтрация - размытие, изменение резкости и т.д.\n",
    "- рандомная зачистка - удаление части исходной картинки \n",
    "\n",
    "Для текста можно использовать: \n",
    "- перемешивание слов/предложений \n",
    "- перестановка слов - замена слов синонимами \n",
    "- манипуляция с текстом - перефразирование предложений\n",
    "\n",
    "Для аудио можно использовать: \n",
    "- добавление шумов \n",
    "- смещение каналов \n",
    "- изменение скорости \n",
    "\n",
    "Это только малая часть альбументаций, которую можно использовать. На самом деле их существует намного и намного больше. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим наглядно, что такое альбументации. Использовать будем датасет MNIST, весь датасет нам не понадобится, только пара картинок оттуда. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим обучающую выборку в папку data. Сами данные преобразуем в список, чтобы дальше было удобнее работать. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = list(\n",
    "    torchvision.datasets.MNIST(\n",
    "        \"data\", train=True, transform=None, download=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "for info in src_data:\n",
    "    img, label = info \n",
    "    images.append(np.array(img))\n",
    "    labels.append(label)\n",
    "\n",
    "print(f\"Number of images: {len(images)}\")\n",
    "print(f\"Number of labels: {len(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все картинки нам, конечно, не понадобится, возьмём только пару из них для наглядности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем применить к нашим картинкам сдвиг, для наглядности заполним белым цветом пиксели, которые появятся в результате сдвига. Но в реальных условиях лучше выбирать цвет исходя из данных. \n",
    "\n",
    "Например, у нас в данных фон чёрный, логичнее было бы заполнять недостающие пиксели чёрным. \n",
    "\n",
    "Важно также упомянуть, что параметр `p` отвечает за вероятность применения альбументации, в нашем примере он выставлен в `p = 0.9`, чтобы как можно чаще получать изменённую картинку, в реальной задаче такая частота изменения может пагубно сказаться на обучении модели, так что лучше устанавливать значение поменьше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.ShiftScaleRotate(\n",
    "    shift_limit=0.3,\n",
    "    scale_limit=0,\n",
    "    rotate_limit=0,\n",
    "    interpolation=3,\n",
    "    border_mode=cv2.BORDER_CONSTANT,\n",
    "    p=0.9,\n",
    "    value=255,  # white background for better representation\n",
    ")\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Исходное изображение\")\n",
    "\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Изменённое изображение\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сейчас у нас параметры `scale_limit` и `rotate_limit` выставлены в 0, но если установить там значения, то к изображению будут применяться сразу 3 альбументации: сдвиг, изменение масштаба и поворот. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно использовать отражение изображения по вертикальной или/и горизонтальной оси. \n",
    "\n",
    "Однако с этим нужно быть аккуратным, т.к. в задаче распознвания цифр, например, такая альбументация может сделать только хуже. Посколько при написании цифр люди зачастую не пишут их наоборот, верно. Таким образом, если мы модели покажем отражённые цифры это может ввести её в заблуждение. \n",
    "\n",
    "Но мы с вами посмотрим как это выглядит (="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.HorizontalFlip(p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Исходное изображение\")\n",
    "\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Изменённое изображение\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме геометрических преобразований можно использовать различные шумы, например, размытие Гаусса. \n",
    "\n",
    "Здесь также как и во всех примерах `p = 0.9` - учтите это при реальных разработках. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.GaussianBlur(blur_limit=3, p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Исходное изображение\")\n",
    "\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Изменённое изображение\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того можно инвертировать цвета, т.е в нашем случае черное станет белым, а белое, наоборот, чёрным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.InvertImg(p=0.9)\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Исходное изображение\")\n",
    "\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Изменённое изображение\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно создать сразу \"список\" альбументацией, которые будут применяться рандомно.\n",
    "\n",
    "Конструкция `albu.Oneof`, будет выбирать одну альбументацию из списка и применять к картинке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = albu.Compose(\n",
    "    [\n",
    "        albu.OneOf(\n",
    "            [\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0.5,\n",
    "                    scale_limit=0,\n",
    "                    rotate_limit=0,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0,\n",
    "                    scale_limit=0.5,\n",
    "                    rotate_limit=0,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.ShiftScaleRotate(\n",
    "                    shift_limit=0,\n",
    "                    scale_limit=0,\n",
    "                    rotate_limit=50,\n",
    "                    interpolation=3,\n",
    "                    border_mode=cv2.BORDER_CONSTANT,\n",
    "                    p=0.9,\n",
    "                    value=255,  # white background for better representation\n",
    "                ),\n",
    "                albu.InvertImg(p=0.9)\n",
    "            ]\n",
    "        )\n",
    "    ], \n",
    "    p=1, \n",
    ")\n",
    "\n",
    "@interact\n",
    "def show(ind=IntSlider(val=0, min=0, max=len(images)-1)):\n",
    "    _, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 16))\n",
    "\n",
    "    img = images[ind]\n",
    "    transformed_img = transform(image=img)[\"image\"]\n",
    "\n",
    "    ax[0].imshow(img, cmap=\"gray\")\n",
    "    ax[1].imshow(transformed_img, cmap=\"gray\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При применении альбументаций, исходное изображение не всегда меняется (это зависит от значения вероятности `p`). Чем ниже это значение, тем больше шансов, что исходное изоображение не будет как-то изменено - это сделано осознанно, т.к. при обучении модели важнее, чтобы она уловила общую зависимость из исходных данных. Если мы будем подавать модели только изменённые данные, то она может начать ошибаться на исходных данных - а нам оно надо? Конечно, нет (= \n",
    "\n",
    "Это как, у меня нет ключа, но у меня есть кое-что получше - рисунок ключа (= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для применения альбументаций удобно вынести определённый список в отдельный класс и дальше при генерации данных использовать его. \n",
    "\n",
    "Можно использовать класс для изменения обучающих данных, чтобы сразу научить модель всяким искажениям в данных и показать ей, как неидеален реальный мир. \n",
    "\n",
    "Либо, можно оценить работу модели на данных с альбументациями, чтобы понять насколько модель устойчива к искажением и с какими изменениями она совсем не может справиться. Но в этом случае важно понимать, что нельзя сравнивать метрики, полученные на исходной тестовой выборке (без альбументацие) и с альбументациями, такое сравнение будет некорректно, т.к. по сути наборы данных разные. \n",
    "\n",
    "Далее приведён пример класса, но не забывайте, что под каждую задачу, нужно выбирать свой список альбументацией, который больше всего подходит. Успехов! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbuAugmentation:\n",
    "    def __init__(self):\n",
    "        ssr_params = dict(\n",
    "            shift_limit=0.1,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=10,\n",
    "            interpolation=3,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            p=0.5,\n",
    "        )\n",
    "\n",
    "        self.description = [\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.GaussNoise(p=0.5),\n",
    "                    albu.MultiplicativeNoise(per_channel=True, p=0.3),\n",
    "                ],\n",
    "                p=0.4,\n",
    "            ),\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.MotionBlur(blur_limit=3, p=0.2),\n",
    "                    albu.MedianBlur(blur_limit=3, p=0.2),\n",
    "                    albu.GaussianBlur(blur_limit=3, p=0.2),\n",
    "                    albu.Blur(blur_limit=3, p=0.2),\n",
    "                ],\n",
    "                p=0.2,\n",
    "            ),\n",
    "            albu.OneOf(\n",
    "                [\n",
    "                    albu.CLAHE(),\n",
    "                    albu.Sharpen(),\n",
    "                    albu.RandomBrightnessContrast(),\n",
    "                ],\n",
    "                p=0.3,\n",
    "            ),\n",
    "            albu.ShiftScaleRotate(**ssr_params, value=(0,)),\n",
    "        ]\n",
    "        self.compose = albu.Compose(self.description, p=1)\n",
    "\n",
    "    def __call__(self, img: np.ndarray) -> list:\n",
    "        transformed = self.compose(img)\n",
    "        return transformed[\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "\n",
    "* [Albumentations for image classififcation](https://albumentations.ai/docs/getting_started/image_augmentation/)\n",
    "* [List of albumentations](https://albumentations.ai/docs/getting_started/transforms_and_targets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c635c84616f3a4480481715ba1e3be1dbeefd6854b0fa1993fac6b8836a8b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python38064bitvenvvenv56dbb7538548403dbaef87f280de9c9a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
