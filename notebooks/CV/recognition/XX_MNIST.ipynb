{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз мы будем использовать датасет MNIST, который содержить около 60 000 картинок с цифрами, которые были написаны отруки. Каждая картинка в нём имеет размер 28х28 пикселей. Цифры: от 0 до 9. \n",
    "\n",
    "То есть в этом случае мы имеем дело с мультиклассовой классификацией. \n",
    "\n",
    "> MNIST расшифровывается как Modified National Institute of Standart and Technology. \n",
    "\n",
    "Сначала импортируем все необходимые библиотеки. \n",
    "\n",
    "> Для распознавания будем использовать torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем параметры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = { \n",
    "    \"input_size\": 784,      # 28x28 \n",
    "    \"hidden_size_1\": 200,   # размер 1-го скрытого слоя\n",
    "    \"hidden_size_2\": 150,   # размер 2-го скрытого слоя\n",
    "    \"hidden_size_3\": 100,   # размер 3-го скрытого слоя\n",
    "    \"hidden_size_4\": 80,    # размер 4-го скрытого слоя \n",
    "    \"output\": 10,           # кол-во выходов сети (т.к. цифры от 0 до 9)\n",
    "    \"bach_size\": 100,\n",
    "    \"lr_rate\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные, повезло, что в библиотеке torchvision уже есть функция, которая всё сделает за нас. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем обучающую выборку \n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем тестовую выборку\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=False, transform=transforms.ToTensor(), download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём лоядеры данных. Эти лоадеры прослойкой между выборками и кодом модели, так как модель ожидает данные в определённой форме, лоадер делает эту \"грязную\" работу за нас. Что есть удобство! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                  batch_size=CONFIG[\"bach_size\"],shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(dataset=test_data, \n",
    "                                  batch_size=CONFIG[\"bach_size\"],shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iter(train_dataloader)\n",
    "samples,labels=next(data)\n",
    "print(f\"number of samples{samples.shape}\")\n",
    "print(f\"number of labels {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на картинки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='BuPu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что все люди пишут цифры по-разному, и временами даже сам человек не может быть до конца уверен, что за цифра на картинке. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем класс самой модели, которая будет обучаться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size, output):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_size,hidden_size1)\n",
    "        self.f_connected2=nn.Linear(hidden_size1,hidden_size2)\n",
    "        self.f_connected3=nn.Linear(hidden_size2,hidden_size3)\n",
    "        self.f_connected4=nn.Linear(hidden_size3,hidden_size)\n",
    "        self.out_connected=nn.Linear(hidden_size,output)\n",
    "\n",
    "    def forward(self,x):\n",
    "            out=F.relu(self.f_connected1(x)) \n",
    "            out=F.relu(self.f_connected2(out))\n",
    "            out=F.relu(self.f_connected3(out))\n",
    "            out=F.relu(self.f_connected4(out))\n",
    "            out=self.out_connected(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `nn.Module` - это класс из pytorch, его можно рассматривать как довольно \"удобного\" родителя для своих моделей. \n",
    "* `nn.Linear` - это линейный слой\n",
    "*  `F.relu` - функция активации relu (вообще внутри torch есть много разных уже реализованных функций активации: relu, leaky relu, softmax, sigmoid etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте создадим объект нашей модели, а параметры для неё возьмём из конфига. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST(\n",
    "    input_size=CONFIG[\"input_size\"], \n",
    "    hidden_size1=CONFIG[\"hidden_size_1\"],\n",
    "    hidden_size2=CONFIG[\"hidden_size_2\"], \n",
    "    hidden_size3=CONFIG[\"hidden_size_3\"], \n",
    "    hidden_size=CONFIG[\"hidden_size_4\"], \n",
    "    output=CONFIG[\"output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посмотреть из чего вообще состоит модель, можно воспользовать print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы используете уже предобученную модель из torch, то print тоже будет работать и покажет вам весь внутренний мир модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше определяем функцию потерь и метод, по которому будет считаться градиент. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция потерь\n",
    "loss=nn.CrossEntropyLoss()\n",
    "# алгоритм для расчёта градиентного спуска \n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=CONFIG[\"lr_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это была подготовительная стадия. Теперь давайте организуем цикл для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        images = images.reshape(-1, 28 * 28)\n",
    "        output=model(images)\n",
    "        loss_value = loss(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step() \n",
    "    \n",
    "    print(f\"Train. Epoch: {epoch}, loss={loss_value.item()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    for images,labels in test_dataloader:\n",
    "        images=images.reshape(-1,784)\n",
    "        output=model(images) #applying the model we have built\n",
    "        labels=labels\n",
    "        _,prediction=torch.max(output,1)\n",
    "        predicted.append(prediction)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, pred in zip(test_data, prediction):\n",
    "    true_label = image[1]\n",
    "    img = image[0].squeeze(0).cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=[10, 8])\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"true: {true_label} | Pred: {pred}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки \n",
    "\n",
    "* [MNIST Handwritten Digit Recognition Using Pytorch](https://medium.com/analytics-vidhya/training-mnist-handwritten-digit-data-using-pytorch-5513bf4614fb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c635c84616f3a4480481715ba1e3be1dbeefd6854b0fa1993fac6b8836a8b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
