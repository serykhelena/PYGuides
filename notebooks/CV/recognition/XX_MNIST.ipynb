{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Распознавание цифр"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз мы будем использовать датасет MNIST, который содержить около 60 000 картинок с цифрами, которые были написаны отруки. Каждая картинка в нём имеет размер 28х28 пикселей. Цифры: от 0 до 9. \n",
    "\n",
    "То есть в этом случае мы имеем дело с мультиклассовой классификацией. \n",
    "\n",
    "> MNIST расшифровывается как Modified National Institute of Standart and Technology. \n",
    "\n",
    "Сначала импортируем все необходимые библиотеки. \n",
    "\n",
    "> Для распознавания будем использовать torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "CURRENT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем параметры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = { \n",
    "    \"input_size\": 784,      # 28x28 \n",
    "    \"hidden_size_1\": 200,   # размер 1-го скрытого слоя\n",
    "    \"hidden_size_2\": 150,   # размер 2-го скрытого слоя\n",
    "    \"hidden_size_3\": 100,   # размер 3-го скрытого слоя\n",
    "    \"hidden_size_4\": 80,    # размер 4-го скрытого слоя \n",
    "    \"output\": 10,           # кол-во выходов сети (т.к. цифры от 0 до 9)\n",
    "    \"bach_size\": 132,       # обычно используется степень 2-ки\n",
    "    \"lr_rate\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные, повезло, что в библиотеке torchvision уже есть функция, которая всё сделает за нас. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем обучающую выборку \n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем обучающую выборку на обучающую и валидационную выборки\n",
    "# 70% для обучения, 30% для валидации\n",
    "train_size = int(len(train_data) * 0.7)\n",
    "valid_size = len(train_data) - train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем тестовую выборку\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=False, transform=None, download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём лоядеры данных. Эти лоадеры прослойкой между выборками и кодом модели, так как модель ожидает данные в определённой форме, лоадер делает эту \"грязную\" работу за нас. Что есть удобство! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=torch.utils.data.DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=CONFIG[\"bach_size\"],\n",
    "    shuffle=True\n",
    ")\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=valid_data, \n",
    "    batch_size=CONFIG[\"bach_size\"],\n",
    "    shuffle=False\n",
    ")\n",
    "test_dataloader=torch.utils.data.DataLoader(\n",
    "    dataset=test_data, \n",
    "    batch_size=CONFIG[\"bach_size\"],\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=iter(train_dataloader)\n",
    "samples,labels=next(data)\n",
    "print(f\"Number of samples: {samples.shape}\")\n",
    "print(f\"Number of labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте посмотрим на картинки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(samples[i][0],cmap='BuPu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что все люди пишут цифры по-разному, и временами даже сам человек не может быть до конца уверен, что за цифра на картинке. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте напишем класс самой модели, которая будет обучаться. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size, output):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_size, hidden_size1)\n",
    "        self.f_connected2=nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.f_connected3=nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.f_connected4=nn.Linear(hidden_size3, hidden_size)\n",
    "        self.out_connected=nn.Linear(hidden_size, output)\n",
    "\n",
    "    def forward(self,x):\n",
    "            out=F.relu(self.f_connected1(x)) \n",
    "            out=F.relu(self.f_connected2(out))\n",
    "            out=F.relu(self.f_connected3(out))\n",
    "            out=F.relu(self.f_connected4(out))\n",
    "            out=self.out_connected(out)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `nn.Module` - это класс из pytorch, его можно рассматривать как довольно \"удобного\" родителя для своих моделей. \n",
    "* `nn.Linear` - это линейный слой\n",
    "*  `F.relu` - функция активации relu (вообще внутри torch есть много разных уже реализованных функций активации: relu, leaky relu, softmax, sigmoid etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте определимся с устройством, на котором будут выполняться вычисления. Если на вашей машине есть видеокарта и её драйвера установлены правильно, то вы увидите имя 'cuda' в DEVICE, если нет видяхи, то 'cpu'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте создадим объект нашей модели, а параметры для неё возьмём из конфига. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST(\n",
    "    input_size=CONFIG[\"input_size\"], \n",
    "    hidden_size1=CONFIG[\"hidden_size_1\"],\n",
    "    hidden_size2=CONFIG[\"hidden_size_2\"], \n",
    "    hidden_size3=CONFIG[\"hidden_size_3\"], \n",
    "    hidden_size=CONFIG[\"hidden_size_4\"], \n",
    "    output=CONFIG[\"output\"]\n",
    ")\n",
    "# сразу отправить модель на устройство \n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы посмотреть из чего вообще состоит модель, можно воспользовать print."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы используете уже предобученную модель из torch, то print тоже будет работать и покажет вам весь внутренний мир модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дальше определяем функцию потерь и метод, по которому будет считаться градиент. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция потерь\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "# алгоритм для расчёта градиентного спуска \n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=CONFIG[\"lr_rate\"])\n",
    "# создаём сущность, которая автоматически уменьшит шаг обучения в случае, \n",
    "# когда функция потерь перестанет уменьшаться в течение N эпох (patience)\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", patience=10, min_lr=1e-8, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это была подготовительная стадия. Теперь давайте организуем цикл для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "\n",
    "checkpoint_dpath = os.path.join(CURRENT_DIR, \"mnist_checkpoints\")\n",
    "os.makedirs(checkpoint_dpath, exist_ok=True)\n",
    "\n",
    "best_val_loss = None\n",
    "best_metric = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"--- Epoch {epoch} ---\")\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        epoch_loss = []\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "            loader = train_dataloader\n",
    "        else:\n",
    "            model.eval()\n",
    "            loader = valid_dataloader\n",
    "\n",
    "        for images, labels in tqdm(loader, desc=f\"{phase.upper()} Processing\"):\n",
    "            images = images.reshape(-1, 28 * 28)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                print(images.shape)\n",
    "                output=model(images)\n",
    "                loss = criterion(output, labels)\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                epoch_loss.append(loss.item())\n",
    "    \n",
    "        epoch_mean_loss = np.mean(epoch_loss)\n",
    "        print(f\"Stage: {phase.upper()}\\t| Epoch Loss: {epoch_mean_loss:.10f}\")\n",
    "\n",
    "        if phase == \"val\":\n",
    "            if best_val_loss is None or epoch_mean_loss < best_val_loss:\n",
    "                best_val_loss = epoch_mean_loss\n",
    "\n",
    "                checkpoint_path = os.path.join(checkpoint_dpath, \"best.pth\")\n",
    "                print(f\"*** Best state {best_val_loss} saved to {checkpoint_path}\")\n",
    "                save_state = {\"model_state\": model.state_dict()}\n",
    "                torch.save(save_state, checkpoint_path)\n",
    "            else:\n",
    "                scheduler.step(epoch_mean_loss)\n",
    "    \n",
    "    checkpoint_path = os.path.join(checkpoint_dpath, \"last.pth\")\n",
    "    print(f\"* Last state saved to {checkpoint_path}\")\n",
    "    save_state = {\"model_state\": model.state_dict()}\n",
    "    torch.save(save_state, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_2_tensor(image: np.ndarray) -> torch.Tensor:\n",
    "    if len(image.shape) == 2:\n",
    "        image = image[:, :, np.newaxis]\n",
    "\n",
    "    tensor = torch.from_numpy(image)\n",
    "    tensor = tensor.float()\n",
    "    tensor = tensor.div(255)\n",
    "    tensor = tensor.permute(2, 0, 1)\n",
    "    return tensor\n",
    "\n",
    "def tensor_2_image(tensor, dtype=np.uint8, move_channels=False):\n",
    "    if move_channels:\n",
    "        tensor = tensor.permute(1, 2, 0)\n",
    "    np_array = tensor.numpy()\n",
    "    np_array *= 255\n",
    "    np_array = np_array.astype(dtype)\n",
    "\n",
    "    return np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class Inference:\n",
    "    def __init__(self, model, device) -> None:\n",
    "        self._logger = logging.getLogger(self.__class__.__name__)\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "    def _prepare_model(self):\n",
    "        if self._device is None:\n",
    "            self._device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self._device = torch.device(self._device)\n",
    "\n",
    "        self._model.eval()\n",
    "        self._model = self._model.to(self._device)\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, fpath: str, device=None, **kwargs):\n",
    "        if device is None:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        model_chk = torch.load(fpath, map_location=device)\n",
    "\n",
    "        return cls.from_checkpoint(model_chk, device=device, **kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_checkpoint(cls, checkpoint_state: dict, **kwargs):\n",
    "        model_state = checkpoint_state[\"model_state\"]\n",
    "\n",
    "        model = MNIST(\n",
    "            input_size=CONFIG[\"input_size\"], \n",
    "            hidden_size1=CONFIG[\"hidden_size_1\"],\n",
    "            hidden_size2=CONFIG[\"hidden_size_2\"], \n",
    "            hidden_size3=CONFIG[\"hidden_size_3\"], \n",
    "            hidden_size=CONFIG[\"hidden_size_4\"], \n",
    "            output=CONFIG[\"output\"]\n",
    "        )\n",
    "        model.load_state_dict(model_state)\n",
    "\n",
    "        obj_ = cls(model=model, **kwargs)\n",
    "        return obj_\n",
    "    \n",
    "    def get_prediction(self, image: np.ndarray):\n",
    "        image = image.reshape(-1, 28 * 28) \n",
    "        # переводим массив в тензор\n",
    "        image_t = torch.from_numpy(image)\n",
    "        image_t = image_t.float()\n",
    "        image_t = image_t.to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(image_t)\n",
    "            _,prediction=torch.max(output,1)\n",
    "        \n",
    "        return prediction.tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fpath = os.path.join(checkpoint_dpath, \"best.pth\")\n",
    "infer = Inference.from_file(model_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def show_predictions(index=IntSlider(val=0, min=0, max=len(test_data)-1)):\n",
    "    test_img, true_label = test_data[index]\n",
    "    test_img = np.array(test_img)\n",
    "    \n",
    "    pred_label = infer.get_prediction(test_img)\n",
    "\n",
    "    plt.figure(figsize=[5, 5])\n",
    "    plt.imshow(test_img, cmap=\"gray\")\n",
    "    print(f\"True Label: {true_label}\")\n",
    "    print(f\"Predicted Label: {pred_label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки \n",
    "\n",
    "* [MNIST Handwritten Digit Recognition Using Pytorch](https://medium.com/analytics-vidhya/training-mnist-handwritten-digit-data-using-pytorch-5513bf4614fb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c635c84616f3a4480481715ba1e3be1dbeefd6854b0fa1993fac6b8836a8b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
