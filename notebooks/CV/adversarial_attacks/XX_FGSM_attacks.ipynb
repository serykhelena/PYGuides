{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Fast Gradient Sign Method (FGSM) - это простой, но эффективный метод для генерации состязательного изображения. \n",
    "Этот метод был представлен в статье [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572) в 2014 году. \n",
    "\n",
    "Алгоритм FGSM\n",
    "1. Берём исходное изображение \n",
    "2. Получаем предсказание, используя обученную CNN \n",
    "3. Вычисляем значение функции потерь \n",
    "4. Вычисляем градиент по отношению к исходному изображению \n",
    "5. Вычисляем знак градиента \n",
    "6. С использование знакового градиента генерирует состязательную картинку с шумами \n",
    "\n",
    "<center>Формула для FGSM</center>\n",
    "\n",
    "$$ \\text{adv\\_x} = x + \\epsilon * sign(\\nabla_xJ(\\theta, x, y)) $$\n",
    "\n",
    "где \n",
    "* $\\text{adv\\_x}$ - наша выходная картинка с шумами \n",
    "* $x$ - исходное входное изображение \n",
    "* $y$ - истинные классы для входного изображения \n",
    "* $\\epsilon$ - малый коэффициент, на который мы умножаем знаковый градиент. Это значение гарантирует, что полученные шумы будут достаточно малы, чтобы человеческий глаз не заметил подвоха \n",
    "* $\\theta$ - нейронная сеть \n",
    "* $J$ - функция потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "random_seed = 42\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "CURRENT_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "CV_DIR = os.path.abspath(os.path.join(CURRENT_DIR, os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем тестовую выборку\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    \"mnist_content\", train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True\n",
    ")\n",
    "\n",
    "test_dataloader=torch.utils.data.DataLoader(\n",
    "    dataset=test_data, \n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем нашу обученную модель (модель была обучена в ноутбуке - `recognition/XX_MNIST.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size, output):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_size, hidden_size1)\n",
    "        self.f_connected2=nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.f_connected3=nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.f_connected4=nn.Linear(hidden_size3, hidden_size)\n",
    "        self.out_connected=nn.Linear(hidden_size, output)\n",
    "\n",
    "    def forward(self,x):\n",
    "            out=F.relu(self.f_connected1(x)) \n",
    "            out=F.relu(self.f_connected2(out))\n",
    "            out=F.relu(self.f_connected3(out))\n",
    "            out=F.relu(self.f_connected4(out))\n",
    "            out=self.out_connected(out)\n",
    "            return out\n",
    "\n",
    "CONFIG = { \n",
    "    \"input_size\": 784,      # 28x28 \n",
    "    \"hidden_size_1\": 200,   # размер 1-го скрытого слоя\n",
    "    \"hidden_size_2\": 150,   # размер 2-го скрытого слоя\n",
    "    \"hidden_size_3\": 100,   # размер 3-го скрытого слоя\n",
    "    \"hidden_size_4\": 80,    # размер 4-го скрытого слоя \n",
    "    \"output\": 10,           # кол-во выходов сети (т.к. цифры от 0 до 9)\n",
    "    \"bach_size\": 132,       # обычно используется степень 2-ки\n",
    "    \"lr_rate\": 0.01\n",
    "}\n",
    "\n",
    "model = MNIST(\n",
    "    input_size=CONFIG[\"input_size\"], \n",
    "    hidden_size1=CONFIG[\"hidden_size_1\"],\n",
    "    hidden_size2=CONFIG[\"hidden_size_2\"], \n",
    "    hidden_size3=CONFIG[\"hidden_size_3\"], \n",
    "    hidden_size=CONFIG[\"hidden_size_4\"], \n",
    "    output=CONFIG[\"output\"]\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "MODEL_FPATH = os.path.join(CV_DIR, \"recognition\", \"mnist_checkpoints\", \"best.pth\")\n",
    "model.load_state_dict(torch.load(MODEL_FPATH)[\"model_state\"])\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, data_grad):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack( model, device, test_loader, epsilon ):\n",
    "    # Accuracy counter\n",
    "    correct = 0\n",
    "    adv_examples = []\n",
    "\n",
    "    # Loop over all examples in test set\n",
    "    for data, target in test_loader:\n",
    "        # Send the data and label to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Set requires_grad attribute of tensor. Important for Attack\n",
    "        data.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        output = model(data.reshape(-1, 28 * 28))\n",
    "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "\n",
    "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
    "        if init_pred.item() != target.item():\n",
    "            continue\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = F.nll_loss(output, target)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grad = data.grad.data\n",
    "\n",
    "        # Call FGSM Attack\n",
    "        perturbed_data = fgsm_attack(data.reshape(-1, 28 * 28), epsilon, data_grad.reshape(-1, 28 * 28))\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        output = model(perturbed_data)\n",
    "\n",
    "        # Check for success\n",
    "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        if final_pred.item() == target.item():\n",
    "            correct += 1\n",
    "            # Special case for saving 0 epsilon examples\n",
    "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "        else:\n",
    "            # Save some adv examples for visualization later\n",
    "            if len(adv_examples) < 5:\n",
    "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
    "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    final_acc = correct/float(len(test_loader))\n",
    "    print(f\"Epsilon: {epsilon}\\tTest Accuracy = {correct} / {len(test_loader)} = {final_acc}\")\n",
    "\n",
    "    # Return the accuracy and an adversarial example\n",
    "    return final_acc, adv_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
    "\n",
    "accuracies = []\n",
    "examples = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    acc, ex = test_attack(model, DEVICE, test_dataloader, eps)\n",
    "    accuracies.append(acc)\n",
    "    examples.append(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(epsilons, accuracies, \"*-\")\n",
    "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "plt.xticks(np.arange(0, .35, step=0.05))\n",
    "plt.title(\"Accuracy vs Epsilon\")\n",
    "plt.xlabel(\"Epsilon\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot several examples of adversarial samples at each epsilon\n",
    "cnt = 0\n",
    "plt.figure(figsize=(8,10))\n",
    "for i in range(len(epsilons)):\n",
    "    for j in range(len(examples[i])):\n",
    "        cnt += 1\n",
    "\n",
    "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "        if j == 0:\n",
    "            plt.ylabel(f\"Eps: {epsilons[i]}\", fontsize=14)\n",
    "        orig, adv, ex = examples[i][j]\n",
    "        plt.title(f\"{orig} -> {adv}\")\n",
    "        plt.imshow(ex.reshape(28, 28), cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки \n",
    "\n",
    "* [FGSM Tutorial](https://pytorch.org/tutorials/beginner/fgsm_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34c635c84616f3a4480481715ba1e3be1dbeefd6854b0fa1993fac6b8836a8b2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
